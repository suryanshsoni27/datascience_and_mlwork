{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is from tutorial by machine learning with phil\n",
    "\n",
    "import tensorflow_datasets as tfds \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
    }
   ],
   "source": [
    "dataset , info = tfds.load('imdb_reviews/subwords8k',with_info = True,as_supervised = True)\n",
    "\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "encoder = info.features['text'].encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n391/391 [==============================] - 335s 858ms/step - loss: 0.6530 - accuracy: 0.6029 - val_loss: 0.5116 - val_accuracy: 0.7719\nEpoch 2/5\n391/391 [==============================] - 334s 854ms/step - loss: 0.3714 - accuracy: 0.8463 - val_loss: 0.3480 - val_accuracy: 0.8635\nEpoch 3/5\n391/391 [==============================] - 322s 825ms/step - loss: 0.2599 - accuracy: 0.9017 - val_loss: 0.3554 - val_accuracy: 0.8672\nEpoch 4/5\n391/391 [==============================] - 327s 836ms/step - loss: 0.2156 - accuracy: 0.9235 - val_loss: 0.3363 - val_accuracy: 0.8656\nEpoch 5/5\n391/391 [==============================] - 329s 841ms/step - loss: 0.1824 - accuracy: 0.9372 - val_loss: 0.3569 - val_accuracy: 0.8615\n"
    }
   ],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "padded_shapes = ([None],())\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,padded_shapes=padded_shapes)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE,padded_shapes=padded_shapes)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "tf.keras.layers.Dense(64,activation='relu'),\n",
    "tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset,epochs =5, validation_data=test_dataset,validation_steps=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec,size):\n",
    "    zeros = [0]*(size-len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec\n",
    "\n",
    "def sample_predict(sentence,pad):\n",
    "    encoded_sample_pred_text = encoder.encode(sentence)\n",
    "    if pad:\n",
    "        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text,64)\n",
    "\n",
    "        encoded_sample_pred_Text = tf.cast(encoded_sample_pred_text,tf.float32)\n",
    "        predictions = model.predict(tf.expand_dims(encoded_sample_pred_text,0))\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "prob ths is positive review 82.54\nprob ths is positive review 45.43\n"
    }
   ],
   "source": [
    "sample_text = ('This movie is awesome. Acting is really really awesome good')\n",
    "\n",
    "predictions = sample_predict(sample_text,pad=True) * 100\n",
    "\n",
    "print('prob ths is positive review %.2f' % predictions)\n",
    "\n",
    "sample_text = ('this movie is so so, acting was medicorce')\n",
    "\n",
    "predictions = sample_predict(sample_text,pad=True) * 100\n",
    "\n",
    "print('prob ths is positive review %.2f' % predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_to_size_upgraded(vec,size):\n",
    "    zeros = [0]*(size-len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec\n",
    "\n",
    "def sample_predict_upgraded(sentence,pad,model_):\n",
    "    encoded_sample_pred_text = encoder.encode(sentence)\n",
    "    if pad:\n",
    "        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text(64))\n",
    "\n",
    "        encoded_sample_pred_Text = tf.cast(encoded_sample_pred_Text,tf.float32)\n",
    "        predictions = model_.predict(tf.expand_dims(encoded_sample_pred_text,0))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(encoder.vocab_size,64),tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "tf.keras.layers.Dense(64,activation='relu'),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer= tf.keras.optimizers.Adam(1e-4),metrics= ['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset,epochs=5,validation_data = test_dataset,validation_steps=30)\n",
    "\n",
    "\n",
    "\n",
    "sample_text = ('this movie is awesome , acting is good')\n",
    "\n",
    "predictions = sample_predict_upgraded(sample_text,pad=True,model_ = model) * 100\n",
    "\n",
    "print('prob ths is positive review %.2f' % predictions)\n",
    "\n",
    "sample_text = ('this movie is so so, acting was medicorce)\n",
    "\n",
    "predictions = sample_predict_upgraded(sample_text,pad=True,model_ = model) * 100\n",
    "\n",
    "print('prob ths is negative review %.2f' % predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "engine.say(\"hello kiran gulli pulli\")\n",
    "engine.runAndWait()\n",
    "engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['MacBook Pro Microphone', 'MacBook Pro Speakers', 'ZoomAudioDevice']"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "mic = sr.Microphone()\n",
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Device index out of range (3 devices available; device index should be between 0 and 2 inclusive)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-44a07cbeb0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmic\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML/MLwork/lib/python3.7/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# obtain device count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ensure device index is in range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Device index out of range ({} devices available; device index should be between 0 and {} inclusive)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mdevice_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_info_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_input_device_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Device index out of range (3 devices available; device index should be between 0 and 2 inclusive)"
     ]
    }
   ],
   "source": [
    "mic = sr.Microphone(device_index=0)\n",
    "\n",
    "with mic as source:\n",
    "    audio = r.listen(source)\n",
    "\n",
    "data = r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitmlworkvenv3afc1b8f7d2a4b5899fe6159d1eaa597",
   "display_name": "Python 3.7.3 64-bit ('MLwork': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}